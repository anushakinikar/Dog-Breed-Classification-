# -*- coding: utf-8 -*-
"""dogs_bread_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WXGfBAQYkaA_rqdwiXVtrqMGNo7UmJ-H
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import xml.etree.ElementTree as ET
import json
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from PIL import Image
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import cv2

def load_annotations(annotations_folder):
    annotations = {}

    # Iterate through subfolders
    for subfolder in os.listdir(annotations_folder):
        subfolder_path = os.path.join(annotations_folder, subfolder)

        # Check if the path is a directory
        if not os.path.isdir(subfolder_path):
            continue

        # Iterate through XML files in the subfolder
        for xml_file in os.listdir(subfolder_path):
            xml_path = os.path.join(subfolder_path, xml_file)

            # Parse the XML file
            tree = ET.parse(xml_path)
            root = tree.getroot()

            # Extract annotation information
            filename = root.find('filename').text
            folder = root.find('folder').text  # This should be the subfolder name
            image_path = os.path.join(subfolder, filename)

            bndbox = root.find('.//bndbox')
            xmin = int(bndbox.find('xmin').text)
            ymin = int(bndbox.find('ymin').text)
            xmax = int(bndbox.find('xmax').text)
            ymax = int(bndbox.find('ymax').text)

            # Extract class label
            label = root.find('.//object/name').text

            if not isinstance(filename, str):
                filename = str(filename)

            annotations[filename] = {
                'image_path': image_path,
                'bbox': (xmin, ymin, xmax, ymax),
                'label': label
            }

    return annotations

# Load the annotations
annotations_folder = '/content/drive/MyDrive/annotations/Annotation'
annotations = load_annotations(annotations_folder)
print(annotations)

def crop_image(image_path, bbox):
    with Image.open(image_path) as img:
        cropped_img = img.crop(bbox)
        return cropped_img

def resize_image(image, size):
    return image.resize(size, Image.ANTIALIAS)

def image_to_np_array(image):
    return np.array(image)

# Target size for all images (width, height)
target_size = (224, 224)

# Lists to store cropped images and labels
cropped_images_np = []
labels = []

# Iterate over each image data, crop and resize the image
base_path = '/content/drive/MyDrive/images/Images'
for key, item in annotations.items():
    image_path = os.path.join(base_path,item["image_path"]+'.jpg')
    bbox = item["bbox"]
    label = item["label"]

    cropped_img = crop_image(image_path, bbox)
    resized_img = resize_image(cropped_img, target_size)
    cropped_img_np = image_to_np_array(resized_img)
    cropped_images_np.append(cropped_img_np)
    labels.append(label)

# Convert the list of NumPy arrays and labels to NumPy arrays
cropped_images_np_array = np.array(cropped_images_np)
labels_np_array = np.array(labels)

# Verify the shapes of the resulting NumPy arrays
print("Shape of the NumPy array containing cropped images:", cropped_images_np_array.shape)
print("Shape of the NumPy array containing labels:", labels_np_array.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(cropped_images_np_array, labels_np_array, test_size=0.2, random_state=42)
X_train = X_train / 255.0
X_test = X_test / 255.0

from sklearn.preprocessing import LabelEncoder

# Create a LabelEncoder object
label_encoder = LabelEncoder()

# Fit the encoder on your labels and transform them
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
data_augmentation = ImageDataGenerator(
    rotation_range=20,
    horizontal_flip=True,
    zoom_range=0.2,
    fill_mode='nearest'
)

import tensorflow as tf
from tensorflow.keras import layers, models
model = models.Sequential([

    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(data_augmentation.flow(X_train, y_train, batch_size=64), epochs=10, validation_data=(X_test, y_test))

model.fit(data_augmentation.flow(X_train, y_train, batch_size=64), epochs=10, validation_data=(X_test, y_test))

model.save('Dog_Classification.h5')